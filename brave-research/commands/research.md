---
description: Brave Search APIを使ったマルチステップ深掘り調査。トピックを指定して包括的なリサーチレポートを生成する。
argument-hint: "<調査トピック>"
allowed-tools: Bash, Read, Write, AskUserQuestion, WebFetch
model: opus
---

Brave Search API を使ったマルチステップ深掘り調査を実行する。

## 引数の確認

調査トピック: $ARGUMENTS

$ARGUMENTS が空の場合は、AskUserQuestion で調査したいトピックを確認する。

## Core Principles

- **計画なき調査は散漫** -- 検索前にサブトピックを分解する
- **単一ソース依存は危険** -- 複数ソースの交差検証を行う
- **情報過多は逆効果** -- 各ステップで取捨選択する
- **引用なき結論は無価値** -- すべての情報にソースリンクを付与する

## Process

```
PLAN → SEARCH → EXTRACT → VERIFY → SYNTHESIZE → REPORT
                  ↑                    │
                  └── 情報不足時 ──────┘
```

---

## Step 1: PLAN（計画）

調査トピックを分析し、サブトピックに分解する。

### 調査設計

AskUserQuestion で以下を確認する:

- **調査の目的**: 技術選定 / 競合分析 / トレンド把握 / 学習 / その他
- **深度**: 概要レベル / 詳細分析 / 網羅的調査
- **出力形式**: 会話内テキスト / Markdown ファイル保存

### サブトピック分解

トピックを 3〜5 のサブトピックに分解し、各サブトピックに検索クエリを設計する:

```markdown
## 調査計画: [トピック]

### サブトピック
1. [サブトピック1] → クエリ: "[検索クエリ1]"
2. [サブトピック2] → クエリ: "[検索クエリ2]"
3. [サブトピック3] → クエリ: "[検索クエリ3]"
```

計画をユーザーに提示し、承認を得てから実行に移る。

---

## Step 2: SEARCH（検索）

各サブトピックを順次検索する。

```bash
# サブトピック1
uv run --with requests ${CLAUDE_PLUGIN_ROOT}/scripts/search.py "クエリ1" -c 10

# サブトピック2
uv run --with requests ${CLAUDE_PLUGIN_ROOT}/scripts/search.py "クエリ2" -c 10

# サブトピック3（ニュース）
uv run --with requests ${CLAUDE_PLUGIN_ROOT}/scripts/search.py "クエリ3" -t news -c 5 --freshness pm
```

各検索結果から有望なソース（3〜5件）を選定する。

---

## Step 3: EXTRACT（抽出）

選定したソースのコンテンツを抽出する。

```bash
uv run --with requests --with readability-lxml --with lxml_html_clean ${CLAUDE_PLUGIN_ROOT}/scripts/extract.py "URL" --max-length 5000
```

抽出したコンテンツから以下を記録する:
- 主要な事実・データ
- 引用すべきポイント
- 他ソースとの矛盾点

---

## Step 4: VERIFY（検証）

収集した情報の交差検証を行う:

- 複数ソースで一致する情報は信頼度が高い
- 単一ソースのみの主張には注意を付記
- 日付の新しい情報を優先
- 公式ドキュメントや一次情報を重視

情報が不足している場合は Step 2 に戻り、追加クエリで補完する。

---

## Step 5: SYNTHESIZE（統合）

全情報を構造化レポートにまとめる。

### レポート構成

```markdown
# 調査レポート: [トピック]

## 要約
[3〜5文の要約]

## 主要な発見

### [サブトピック1]
[発見内容]
- 出典: [URL]

### [サブトピック2]
[発見内容]
- 出典: [URL]

### [サブトピック3]
[発見内容]
- 出典: [URL]

## 分析と考察
[情報の統合分析、トレンド、示唆]

## 注意事項・限界
[情報の鮮度、バイアス、未確認事項]

## 参考文献
1. [タイトル](URL) - アクセス日: YYYY-MM-DD
2. [タイトル](URL) - アクセス日: YYYY-MM-DD
```

---

## Step 6: REPORT（出力）

ユーザーが選択した出力形式でレポートを提供する:

- **会話内テキスト**: レポートを直接表示
- **ファイル保存**: 指定パスに Markdown ファイルとして保存

---

## Anti-Patterns

- 検索結果を分析せずそのまま貼り付ける（価値がない）
- 1回の検索で調査完了とする（深度が不足）
- 引用リンクを省略する（検証不能）
- すべてのソースを均等に扱う（信頼度の差を無視）
- 古い情報を新しい情報と同等に扱う（鮮度を考慮しない）

---

## コスト意識

Deep Research は複数回の API 呼び出しを伴う。Free プラン（2,000件/月）の場合:

- サブトピック3つ × 10件 = 30 API クエリ消費
- コンテンツ抽出は API クエリを消費しない
- 月間予算を考慮し、必要最小限のクエリで最大の情報を得る
